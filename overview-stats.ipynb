{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696654e4",
   "metadata": {},
   "source": [
    "# OpenAIRE Graph University Overview\n",
    "\n",
    "This notebook fetches summary statistics per university using the [OpenAIRE Graph API](https://graph.openaire.eu/docs/apis/graph-api/). For every listed university we compare three perspectives:\n",
    "\n",
    "- **A. Publications affiliated to the university** – filter on the OpenAIRE OpenORG identifier.\n",
    "- **B. Publications collected by the main (CRIS) data source** – filter on the CRS/data source identifier.\n",
    "- **C. Publications collected by the secondary repository** – filter on the repository identifier when available.\n",
    "\n",
    "For each perspective we retrieve counts for funding/projects, data sources, and research products split into publications, datasets, software, and other research outputs. The notebook separates the data collection steps so that each can be re-run independently when debugging or iterating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib openpyxl python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86519c7f",
   "metadata": {},
   "source": [
    "## 1. Imports and reused constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.float_format\", lambda value: f\"{value:,.0f}\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "\n",
    "if not CLIENT_ID or not CLIENT_SECRET:\n",
    "    raise RuntimeError(\n",
    "        \"Missing OpenAIRE credentials. Set CLIENT_ID and CLIENT_SECRET in the environment.\"\n",
    "    )\n",
    "\n",
    "BASE_URL = \"https://api.openaire.eu/graph\"\n",
    "TOKEN_URL = \"https://aai.openaire.eu/oidc/token\"\n",
    "API_USER_AGENT = \"OpenAIRE-tools overview-stats notebook\"\n",
    "API_PAUSE_SECONDS = 0.1  # throttle requests a bit to stay within rate limits\n",
    "TOKEN_REFRESH_BUFFER = 60  # refresh the token one minute before expiration\n",
    "\n",
    "PRODUCT_TYPE_LABELS = {\n",
    "    \"publication\": \"Publications\",\n",
    "    \"dataset\": \"Research data\",\n",
    "    \"software\": \"Research software\",\n",
    "    \"other\": \"Other research products\",\n",
    "}\n",
    "\n",
    "METRIC_ORDER = [\n",
    "    \"Funding / Projects\",\n",
    "    \"Data sources\",\n",
    "    *PRODUCT_TYPE_LABELS.values(),\n",
    "]\n",
    "\n",
    "COMPARISON_LONG_PATH = \"comparison_long.csv\"\n",
    "COMPARISON_PIVOT_PATH = \"comparison_pivot.csv\"\n",
    "\n",
    "_access_token: Optional[str] = None\n",
    "_access_token_expiry: float = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e359a7",
   "metadata": {},
   "source": [
    "## 2. Parse the university reference table\n",
    "The raw table below mirrors the values supplied in the request. We reshape it into a structured list so that the rest of the notebook can iterate over the entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42836ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_orgs_baseline_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTDQiWDIaI1SZkPTMNCovicBhA-nQND1drXoUKvrG1O_Ga3hLDRvmQZao_TvNgmNQ/pub?output=xlsx\"\n",
    "NL_ORGS_BASELINE_PATH = Path(\"nl_orgs_baseline.xslx\")\n",
    "\n",
    "\n",
    "def download_nl_orgs_baseline(url: str, dest: Path) -> Path:\n",
    "    \"\"\"Download the latest NL organizations baseline and store it locally.\"\"\"\n",
    "    response = requests.get(url, timeout=120)\n",
    "    response.raise_for_status()\n",
    "    dest.write_bytes(response.content)\n",
    "    return dest\n",
    "\n",
    "\n",
    "download_nl_orgs_baseline(nl_orgs_baseline_url, NL_ORGS_BASELINE_PATH)\n",
    "\n",
    "TABLE_PATH = NL_ORGS_BASELINE_PATH\n",
    "\n",
    "\n",
    "def load_university_table(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Load the NL organizations reference table and normalise empty values to blanks.\"\"\"\n",
    "    table_path = Path(path)\n",
    "    if not table_path.exists():\n",
    "        raise FileNotFoundError(f\"Reference table not found: {table_path}\")\n",
    "    excel_suffixes = {\".xlsx\", \".xls\", \".xslx\"}\n",
    "    if table_path.suffix.lower() in excel_suffixes:\n",
    "        df = pd.read_excel(table_path, dtype=str, keep_default_na=False)\n",
    "    else:\n",
    "        df = pd.read_csv(table_path, sep=\"\t\", dtype=str, keep_default_na=False)\n",
    "    return df.fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3bd2d",
   "metadata": {},
   "source": [
    "## 3. Helper functions for the Graph API\n",
    "These functions wrap the REST requests and centralise filter construction per scenario. Each call prints nothing by default so we can reuse them freely in later cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO_DEFS = [\n",
    "    {\n",
    "        \"key\": \"organization\",\n",
    "        \"label\": \"A. OpenORG affiliation\",\n",
    "        \"id_field\": \"openorg_id\",\n",
    "        \"description\": \"Publications affiliated to the university (OpenAIRE OpenORG ID)\",\n",
    "    },\n",
    "    {\n",
    "        \"key\": \"main_datasource\",\n",
    "        \"label\": \"B. Main/CRIS data source\",\n",
    "        \"id_field\": \"main_datasource_id\",\n",
    "        \"description\": \"Publications collected from the main CRIS data source\",\n",
    "    },\n",
    "    {\n",
    "        \"key\": \"secondary_datasource\",\n",
    "        \"label\": \"C. Secondary repository\",\n",
    "        \"id_field\": \"secondary_datasource_id\",\n",
    "        \"description\": \"Publications collected from the secondary / repository data source\",\n",
    "    },\n",
    "]\n",
    "\n",
    "FILTER_BUILDERS = {\n",
    "    \"organization\": lambda entity_id: {\n",
    "        \"projects\": {\"relOrganizationId\": entity_id},\n",
    "        \"dataSources\": {\"relOrganizationId\": entity_id},\n",
    "        \"researchProducts\": {\"relOrganizationId\": entity_id},\n",
    "    },\n",
    "    \"main_datasource\": lambda entity_id: {\n",
    "        \"projects\": {\"relCollectedFromDatasourceId\": entity_id},\n",
    "        \"dataSources\": {\"id\": entity_id},\n",
    "        \"researchProducts\": {\"relCollectedFromDatasourceId\": entity_id},\n",
    "    },\n",
    "    \"secondary_datasource\": lambda entity_id: {\n",
    "        \"projects\": {\"relCollectedFromDatasourceId\": entity_id},\n",
    "        \"dataSources\": {\"id\": entity_id},\n",
    "        \"researchProducts\": {\"relCollectedFromDatasourceId\": entity_id},\n",
    "    },\n",
    "}\n",
    "\n",
    "EMPTY_METRICS = {metric: None for metric in METRIC_ORDER}\n",
    "\n",
    "\n",
    "def obtain_access_token() -> str:\n",
    "    \"\"\"Return a cached OpenAIRE access token, refreshing it when needed.\"\"\"\n",
    "    global _access_token, _access_token_expiry\n",
    "    now = time.time()\n",
    "    if _access_token and now < _access_token_expiry:\n",
    "        return _access_token\n",
    "\n",
    "    response = requests.post(\n",
    "        TOKEN_URL,\n",
    "        data={\"grant_type\": \"client_credentials\"},\n",
    "        auth=(CLIENT_ID, CLIENT_SECRET),\n",
    "        headers={\"User-Agent\": API_USER_AGENT},\n",
    "        timeout=60,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    payload = response.json()\n",
    "    token = payload.get(\"access_token\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"OpenAIRE token response did not include an access_token.\")\n",
    "    expires_in = int(payload.get(\"expires_in\", 3600))\n",
    "    _access_token = token\n",
    "    _access_token_expiry = now + max(expires_in - TOKEN_REFRESH_BUFFER, 0)\n",
    "    return _access_token\n",
    "\n",
    "\n",
    "def call_graph_api(path: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Invoke the OpenAIRE Graph API and return the decoded JSON payload.\"\"\"\n",
    "    url = f\"{BASE_URL}{path}\"\n",
    "    effective_params = dict(params or {})\n",
    "    effective_params.setdefault(\"page\", 1)\n",
    "    effective_params.setdefault(\"pageSize\", 1)\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": API_USER_AGENT,\n",
    "        \"Authorization\": f\"Bearer {obtain_access_token()}\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(\n",
    "        url,\n",
    "        params=effective_params,\n",
    "        headers=headers,\n",
    "        timeout=60,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    time.sleep(API_PAUSE_SECONDS)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def fetch_num_found(path: str, params: Dict[str, Any]) -> Optional[int]:\n",
    "    \"\"\"Return the total number of matching records for the supplied endpoint.\"\"\"\n",
    "    payload = call_graph_api(path, params)\n",
    "    header = payload.get(\"header\", {})\n",
    "    num_found = header.get(\"numFound\")\n",
    "    return int(num_found) if num_found is not None else None\n",
    "\n",
    "\n",
    "def build_filters(scenario_key: str, entity_id: str) -> Dict[str, Dict[str, Any]]:\n",
    "    builder = FILTER_BUILDERS[scenario_key]\n",
    "    return {name: dict(filters) for name, filters in builder(entity_id).items()}\n",
    "\n",
    "\n",
    "def collect_metrics(scenario_key: str, entity_id: Optional[str]) -> Dict[str, Optional[int]]:\n",
    "    if not entity_id:\n",
    "        return deepcopy(EMPTY_METRICS)\n",
    "\n",
    "    filters = build_filters(scenario_key, entity_id)\n",
    "    results: Dict[str, Optional[int]] = {}\n",
    "\n",
    "    results[\"Funding / Projects\"] = fetch_num_found(\"/v1/projects\", filters[\"projects\"])\n",
    "    results[\"Data sources\"] = fetch_num_found(\"/v1/dataSources\", filters[\"dataSources\"])\n",
    "\n",
    "    for rp_type, label in PRODUCT_TYPE_LABELS.items():\n",
    "        rp_params = dict(filters[\"researchProducts\"], type=rp_type)\n",
    "        results[label] = fetch_num_found(\"/v2/researchProducts\", rp_params)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f6ecd",
   "metadata": {},
   "source": [
    "## 4. Sanity check on a single university\n",
    "Run a quick test so we know the API access works before looping over the full list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_university = universities[0]\n",
    "print(f\"Sample university: {sample_university['name']}\")\n",
    "for scenario in SCENARIO_DEFS:\n",
    "    identifier = sample_university.get(scenario[\"id_field\"])\n",
    "    metrics = collect_metrics(scenario[\"key\"], identifier)\n",
    "    print(f\"  {scenario['label']} ({identifier}):\")\n",
    "    for metric in METRIC_ORDER:\n",
    "        print(f\"    - {metric}: {metrics.get(metric)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae22072",
   "metadata": {},
   "source": [
    "## 5. Fetch metrics for all universities\n",
    "This cell iterates over every university and prints intermediate summaries for transparency during execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aggregated_results: list[dict[str, Any]] = []\n",
    "\n",
    "for university in universities:\n",
    "    uni_entry = {\n",
    "        \"info\": university,\n",
    "        \"scenarios\": {},\n",
    "    }\n",
    "    print(f\"\\n=== {university['name']} ===\")\n",
    "    for scenario in SCENARIO_DEFS:\n",
    "        identifier = university.get(scenario[\"id_field\"])\n",
    "        metrics = collect_metrics(scenario[\"key\"], identifier)\n",
    "        uni_entry[\"scenarios\"][scenario[\"key\"]] = metrics\n",
    "\n",
    "        label = scenario[\"label\"]\n",
    "        identifier_display = identifier if identifier else \"no identifier provided\"\n",
    "        print(f\"{label} ({identifier_display}):\")\n",
    "        for metric in METRIC_ORDER:\n",
    "            print(f\"  {metric}: {metrics.get(metric)}\")\n",
    "    aggregated_results.append(uni_entry)\n",
    "\n",
    "print(\"\\nCompleted data collection for all universities.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832fd00",
   "metadata": {},
   "source": [
    "## 6. Assemble and save the comparison table\n",
    "We reshape the collected metrics into both a long format and a pivoted table, then cache them on disk for reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dec8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "records: list[dict[str, Any]] = []\n",
    "for entry in aggregated_results:\n",
    "    base = entry[\"info\"]\n",
    "    for scenario in SCENARIO_DEFS:\n",
    "        metrics = entry[\"scenarios\"].get(scenario[\"key\"], {})\n",
    "        for metric in METRIC_ORDER:\n",
    "            records.append(\n",
    "                {\n",
    "                    \"University\": base[\"name\"],\n",
    "                    \"ROR\": base.get(\"ror\"),\n",
    "                    \"Scenario\": scenario[\"label\"],\n",
    "                    \"Metric\": metric,\n",
    "                    \"Count\": metrics.get(metric),\n",
    "                }\n",
    "            )\n",
    "\n",
    "comparison_df = pd.DataFrame(records)\n",
    "comparison_pivot = (\n",
    "    comparison_df.pivot_table(\n",
    "        index=[\"University\", \"ROR\"],\n",
    "        columns=[\"Scenario\", \"Metric\"],\n",
    "        values=\"Count\",\n",
    "    )\n",
    "    .sort_index(axis=1, level=0)\n",
    "    .astype(\"Int64\")\n",
    ")\n",
    "\n",
    "comparison_df.to_csv(COMPARISON_LONG_PATH, index=False)\n",
    "comparison_pivot.to_csv(COMPARISON_PIVOT_PATH)\n",
    "print(f\"Saved long-format table to {COMPARISON_LONG_PATH}\")\n",
    "print(f\"Saved pivot table to {COMPARISON_PIVOT_PATH}\")\n",
    "comparison_pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735231d9",
   "metadata": {},
   "source": [
    "## 7. Reload saved comparison tables\n",
    "Reload the cached CSV files so downstream steps can run without recomputing the API queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.read_csv(COMPARISON_LONG_PATH)\n",
    "if \"Count\" in comparison_df.columns:\n",
    "    comparison_df[\"Count\"] = comparison_df[\"Count\"].astype(\"Int64\")\n",
    "\n",
    "# Remove problematic row for Uni of Minnesota ('University of Minnesota', '017zqws13') \n",
    "mask = (comparison_df[\"University\"] == \"University of Minnesota\") & (comparison_df[\"ROR\"] == \"017zqws13\")\n",
    "comparison_df = comparison_df.loc[~mask].copy()\n",
    "\n",
    "comparison_pivot = pd.read_csv(\n",
    "    COMPARISON_PIVOT_PATH,\n",
    "    header=[0, 1],\n",
    "    index_col=[0, 1],\n",
    ")\n",
    "comparison_pivot.columns = pd.MultiIndex.from_tuples(comparison_pivot.columns)\n",
    "comparison_pivot = comparison_pivot.astype(\"Int64\")\n",
    "row_key = (\"Uni of Innsbruck\", \"054pv6659\")\n",
    "if row_key in comparison_pivot.index:\n",
    "    comparison_pivot = comparison_pivot.drop(index=row_key)\n",
    "print(f\"Reloaded tables from {COMPARISON_LONG_PATH} and {COMPARISON_PIVOT_PATH}\")\n",
    "comparison_pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410e797",
   "metadata": {},
   "source": [
    "## 8. Visualising publication counts\n",
    "The chart below compares publication totals by affiliation and harvesting source. Missing bars indicate that the corresponding source does not currently expose publications in the OpenAIRE Graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_df = comparison_df[comparison_df[\"Metric\"] == \"Publications\"].copy()\n",
    "wide_publications = (\n",
    "    publication_df.pivot(index=\"University\", columns=\"Scenario\", values=\"Count\")\n",
    "    .reindex(universities_df[\"name\"].tolist())\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "wide_publications.plot(kind=\"bar\", ax=ax)\n",
    "ax.set_xlabel(\"University\")\n",
    "ax.set_ylabel(\"Number of publications\")\n",
    "ax.set_title(\"Publications by affiliation vs. data sources\")\n",
    "ax.legend(title=\"Scenario\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Missing bars indicate that the source may not be connected to OpenAIRE or does not expose publications.\")\n",
    "main_datasource_label = next(\n",
    "    scenario[\"label\"]\n",
    "    for scenario in SCENARIO_DEFS\n",
    "    if scenario[\"key\"] == \"main_datasource\"\n",
    ")\n",
    "if main_datasource_label not in wide_publications.columns:\n",
    "    print(\"\\nNo publication data available for the CRIS data source scenario.\")\n",
    "else:\n",
    "    main_source_counts = wide_publications[main_datasource_label]\n",
    "    has_main_datasource = universities_df[\"main_datasource_id\"].fillna(\"\").str.strip() != \"\"\n",
    "    main_source_publications = universities_df[\"name\"].map(main_source_counts)\n",
    "    no_publications_mask = main_source_publications.isna() | (main_source_publications == 0)\n",
    "    no_publications_cris = universities_df.loc[has_main_datasource & no_publications_mask, \"name\"].tolist()\n",
    "    if no_publications_cris:\n",
    "        print(\"\\nUniversities with a CRIS data source but no publications retrieved from it:\")\n",
    "        for name in no_publications_cris:\n",
    "            print(f\"- {name}\")\n",
    "    else:\n",
    "        print(\"\\nAll CRIS-connected universities have publications retrieved from that data source.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63acc0d9",
   "metadata": {},
   "source": [
    "## 9. Notes and follow-ups\n",
    "- A missing identifier (OpenORG or data source) results in `NA` counts for that scenario.\n",
    "- Some organizations without a dedicated CRIS only contribute repository records, so their main data source column remains empty.\n",
    "- Consider repeating the collection with date filters (e.g. recent years) or cursor-based pagination if you need to validate the totals beyond the `numFound` figures.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}